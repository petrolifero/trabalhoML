\documentclass[12pt]{article}

\usepackage{sbc-template}
\usepackage{graphicx,url}
\usepackage[utf8]{inputenc}
\usepackage[brazil]{babel} 

     
\sloppy

\title{Avaliando previsões de \textit{default} em empréstimos}

\author{João Pedro Abreu de Souza\inst{1}}


\address{Instituto de Computação -- Universidade Federal Fluminense
  (UFF)\\
  \email{jp\_abreu@id.uff.br}
}

\begin{document} 

\maketitle

\begin{abstract}
  This paper model a decision's tree on the problem of determine \textit{default} on loans, the fundamental problem on any credit institution.
\end{abstract}
     
\begin{resumo} 
  Este artigo modela uma árvore de decisão no problema de determinação de \textit{default} em empréstimos, o problema fundamental em qualquer instituição fornecedora de crédito.
  
\end{resumo}


\section{Introdução}

Dentro do mercado de crédito, protagonizado por Bancos, cooperativas de crédito e demais instituições financeiras, a determinação do risco de inadimplência (i.e. \textit{default}) é crucial pois desse risco advém toda a decisão de conceder crédito, e caso conceda, a qual custo deve ser fornecido, de forma que as pessoas ou instituições adimplentes suportem a perda das pessoas ou instituições inadimplentes. O custo minimo, dado um cohort especifico, que deve ser acrescido ao custo dos adimplentes, é dado, segundo \cite{investopedia}, EAD x PD x LGD = Expected Loss. Este artigo relata a utilização de um conjunto de 22999 registros de empréstimos disponível publicamente em \cite{kaggle} para treinar uma arvore de decisão usando \cite{scikit}, \cite{pandas} e \cite{numpy} para tratamento dos dados. Os dados para reprodução do artigo encontram-se em \cite{repositorio}. Para produzir a analise, instale as dependências que estão no arquivo requirements.txt e execute o main.py com python 3.

\section{Limpeza dos dados} \label{sec:firstpage}

O dataset escolhido por esse artigo\cite{dataset} necessitou de uma fase de limpeza bem curta, removendo do csv uma primeira linha de header que estava logicamente duplicada. Como é possivel constatar em kaggle\cite{kaggle}, essa linha possuia a mesma informação do header seguinte, porém com colunas chamadas X1, X2, etc. De posse do dicionario de dados que a pagina fornece, é possivel interpreta-lo, mas foi mais simples apenas não usa-lo em prol de legibilidade. Originalmente foram considerados para esse artigo outros 4 datasets, porém descartados na fase de limpeza, pois possuiam caracteristicas discriminatórias, como local de moradia, ou possuiam multiplas colunas nulas, a fim de contemplar os multiplos pagamentos ou a falta deles. Além disso os datasets descartados, que permanecem nos documentos fornecidos junto ao presente artigo, possuiam uma cardinalidade muito menor que o escolhido. Como o modelo deve ser capaz de ser explicado para quem tiver seu crédito negado, além de atender a restrições legais e éticas, o dataset atual foi finalmente escolhido. A divisão entre as classes é de 17826 casos de default e 5173 casos de adimplência.

\section{Divisão treinamento}

A divisão dos dados originais em treinamento e teste ficou dividido em 30\% para testes e 70\% para treino. A divisão entre teste e treino obedece a divisão padrão do scikit, que é por padrão de 25\%, mas considerando um conjunto maior em comparação aos datasets descartados, foi fornecido um pouco mais aos testes, para aproveitar o tamanho.

\section{Avaliação de performance}
\begin{table}[h]
	\centering
	\begin{tabular}{lcccc}
		\hline
		\textbf{Classe} & \textbf{Precisão} & \textbf{Revocação} & \textbf{F1-Score} & \textbf{Suporte} \\ \hline
		0                & 0.83              & 0.80               & 0.81               & 5375              \\
		1                & 0.37              & 0.41               & 0.39               & 1525              \\ \hline
		\textbf{Precisão Média} & \multicolumn{4}{c}{0.60} \\
		\textbf{Revocação Média} & \multicolumn{4}{c}{0.60} \\
		\textbf{F1-Score Médio} & \multicolumn{4}{c}{0.60} \\
		\textbf{Acurácia} & \multicolumn{4}{c}{0.71} \\
		\textbf{Suporte Total} & \multicolumn{4}{c}{6900} \\ \hline
	\end{tabular}
	\caption{Relatório de classificação para o arquivo Loan-data-sem-primeira-linha-change-dependent-variable.csv}
	\label{tab:class_report}
\end{table}

\section{Conclusão}
Arvore de decisão é uma escolha apropriada para estimar problemas que precisem de explicação concreta e não abstrata, porém mesmo com um dataset com pouco desbalanço comparado a um dataset maior, ainda oferece uma performance relativamente ruim com os parâmetros utilizados. A avaliação foi extremamente rapida, então o trade-off entre performance e baixo custo de operação, seja energético ou ambiental, deve ser levado em conta.

\bibliographystyle{sbc}
\bibliography{sbc-template}

\end{document}
