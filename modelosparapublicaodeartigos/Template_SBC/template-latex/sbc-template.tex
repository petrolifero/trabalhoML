\documentclass[12pt]{article}

\usepackage{sbc-template}
\usepackage{cite}
\usepackage{graphicx,url}
\usepackage[utf8]{inputenc}
\usepackage[brazil]{babel} 
\usepackage{amsmath}
     
\sloppy

\title{Avaliando previsões de \textit{default} em empréstimos}

\author{João Pedro Abreu de Souza\inst{1}}


\address{Instituto de Computação -- Universidade Federal Fluminense
  (UFF)\\
  \email{jp\_abreu@id.uff.br}
}

\begin{document} 

\maketitle

\begin{abstract}
  This paper model a decision's tree on the problem of determine \textit{default} on loans, the fundamental problem on any credit institution.
\end{abstract}
     
\begin{resumo} 
  Este artigo modela uma árvore de decisão no problema de determinação de \textit{default} em empréstimos, o problema fundamental em qualquer instituição fornecedora de crédito.
  
\end{resumo}


\section{Introdução}

Dentro do mercado de crédito, protagonizado por Bancos, cooperativas de crédito e demais instituições financeiras, a determinação do risco de inadimplência (i.e. \textit{default}) de um empréstimo é crucial pois desse risco advém toda a decisão de conceder crédito, e caso conceda, a qual custo deve ser fornecido, de forma que os clientes adimplentes compensem a perda dos inadimplentes. A utilização de árvores de decisão buscando prever se, dado um cliente, o empréstimo, caso concedido, será pago é relevante pois essa família de modelos possui alta capacidade de explicação através dos nós da árvore, permitindo entender de forma pormenorizada o processo decisório do modelo. Com isso, especialistas humanos conseguem criticar o modelo com maior facilidade .O custo mínimo, dado um cohort especifico, que deve ser acrescido ao custo dos adimplentes, é dado, segundo \cite{investopedia}, EAD x PD x LGD = Expected Loss. Este artigo relata a utilização de um conjunto de 22999 registros de empréstimos disponível publicamente em \cite{kaggle} para treinar uma arvore de decisão usando \cite{scikit}, \cite{pandas} e \cite{numpy} para tratamento dos dados. Os dados para reprodução do artigo encontram-se em \cite{repositorio}. Para produzir a analise, instale as dependências que estão no arquivo requirements.txt e execute o main.py com python 3.

\section{Limpeza dos dados} \label{sec:firstpage}

O data set escolhido por esse artigo\cite{dataset} necessitou de uma fase de limpeza bem curta, removendo do csv uma primeira linha de header que estava logicamente duplicada e . Como é possível constatar em kaggle\cite{kaggle}, essa linha possuía a mesma informação do header seguinte, porém com colunas chamadas X1, X2, etc. De posse do dicionario de dados que a pagina fornece, é possível interpreta-lo, mas foi mais simples apenas não usa-lo em prol de legibilidade. Originalmente foram considerados para esse artigo outros 4 data sets, porém foram descartados na fase de limpeza, pois possuíam características discriminatórias, como local de moradia, ou possuíam múltiplas colunas nulas, a fim de contemplar os múltiplos pagamentos ou a falta deles. Com múltiplas colunas iguais, elas não ofereciam ganho de informação. Além disso os data sets descartados, que permanecem nos documentos fornecidos junto ao presente artigo, possuíam uma cardinalidade muito menor que o escolhido. Como o modelo deve ser capaz de ser explicado para quem tiver seu crédito negado, além de atender a restrições legais e éticas, o data set atual foi finalmente escolhido. A divisão entre as classes é de 17826 casos de default e 5173 casos de adimplência.

\section{Divisão treinamento}

A divisão dos dados originais em treinamento e teste ficou dividido em 30\% para testes e 70\% para treino. A divisão entre teste e treino obedece a divisão padrão do scikit, que é por padrão de 25\%, mas considerando um conjunto maior em comparação aos data sets descartados, foi fornecido um pouco mais aos testes, para aproveitar o tamanho.

\section{Avaliação de performance}
\subsection{Explicação das métricas usadas}
Segundo \cite{powers2011evaluation}, temos as seguintes métricas comumente utilizadas em aprendizado de maquina : Precisão, Recall, F1-Score e Support. Estas sendo definidas dependendo da relação entre classes previstas e classes reais do treino. Essas relações são Verdadeiro Positivo (quando o modelo prevê corretamente a classe positiva), Falso Positivo (quando o modelo prevê a classe positiva, mas a classe real é negativa), Verdadeiro Negativo (quando o modelo prevê corretamente a classe negativa) e Falso Negativo (quando o modelo prevê a classe negativa, mas a classe real é positiva). As relações são as que seguem :
\subsection*{Precisão}
\[
\text{Precisão} = \frac{\text{VP}}{\text{VP} + \text{FP}}
\]

\subsection*{Recall}
\[
\text{Recall} = \frac{\text{VP}}{\text{VP} + \text{FN}}
\]

\subsection*{F1-Score}
\[
F1 = 2 \times \frac{\text{Precisão} \times \text{Recall}}{\text{Precisão} + \text{Recall}}
\]

\subsection*{Suporte}
O suporte é o número de ocorrências reais de cada classe no conjunto de dados.
\[
\text{Suporte} = \text{Número total de exemplos em cada classe}
\]
\subsection{Resultado observado das métricas}
Executando de forma irrestrita (altura indefinida até cada nó folha só conter um tipo de \textit{loan\_status}) temos o seguinte resultado
\begin{table}[h]
	\centering
	\begin{tabular}{lcccc}
		\hline
		\textbf{Classe} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support} \\ \hline
		0                & 0.83              & 0.80               & 0.81               & 5375              \\
		1                & 0.37              & 0.41               & 0.39               & 1525              \\ \hline
		\textbf{Precisão Média} & \multicolumn{4}{c}{0.60} \\
		\textbf{Recall Médio} & \multicolumn{4}{c}{0.60} \\
		\textbf{F1-Score Médio} & \multicolumn{4}{c}{0.60} \\
		\textbf{Acurácia} & \multicolumn{4}{c}{0.71} \\
		\textbf{Suporte Total} & \multicolumn{4}{c}{6900} \\ \hline
	\end{tabular}
	\caption{Relatório de classificação para o arquivo Loan-data-sem-primeira-linha-change-dependent-variable.csv}
	\label{tab:class_report}
\end{table}

Porém limitando a altura 10, que exige menos processamento, temos o seguinte

\begin{table}[h]
	\centering
	\begin{tabular}{lcccc}
		\hline
		\textbf{Classe} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support} \\ \hline
		0                & 0.84              & 0.92               & 0.88               & 5375              \\
		1                & 0.59              & 0.40               & 0.47               & 1525              \\ \hline
		\textbf{Acurácia} & \multicolumn{4}{c}{0.81} \\
		\textbf{Média Macro} & 0.72 & 0.66 & 0.68 & 6900 \\
		\textbf{Média Ponderada} & 0.79 & 0.81 & 0.79 & 6900 \\ \hline
	\end{tabular}
	\caption{Relatório de classificação para o arquivo Loan-data-sem-primeira-linha-change-dependent-variable.csv}
	\label{tab:class_report}
\end{table}

As avaliações não mudaram apreciavelmente, mesmo tendo uma limitação severa de altura. Ou seja, as primeiras divisões da árvore fornecem uma boa explicação sem precisar de mais complexidade.

\section{Conclusão}
Arvore de decisão é uma escolha apropriada para estimar problemas que precisem de explicação concreta e não abstrata, porém mesmo com um data set com pouco desbalanço comparado a um data set maior, ainda oferece uma performance relativamente ruim com os parâmetros utilizados. A avaliação foi extremamente rápida, então o trade-off entre performance e baixo custo de operação, seja energético ou ambiental, deve ser levado em conta. Futuros trabalhos devem avaliar a sensibilidade das métricas à altura máxima, para fins de comparação da maxima eficiência energética com menos danos ambientais.
\bibliographystyle{sbc}
\bibliography{sbc-template}

\end{document}
